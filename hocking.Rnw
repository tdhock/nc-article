\newcommand{\sectiontidyr}{Comparisons with other functions for data frames}
\newcommand{\sectiontrackDb}{Capturing all matches from a multi-line text file}
\newcommand{\sectiontimings}{Comparing computation times of R regex packages}
\newcommand{\sectiondf}{Creating new columns from character columns in a data frame}
\newcommand{\sectionrex}{Comparing \pkg{namedCapture} variable argument syntax with \pkg{rex}}
\newcommand{\sectioncomparisons}{Comparisons with other R packages}

\title{Regular expressions and reshaping using data tables and the
  \pkg{nc} package}

\author{by Toby Dylan Hocking}

\maketitle

\abstract{Regular expressions are powerful tools for extracting tables
  from non-tabular text data. Capturing regular expressions that
  describe information to extract from column names can be especially
  useful when reshaping a data table from wide (one row with many
  columns) to tall (one column with many rows). We present the R
  package \pkg{nc}, which provides functions for data reshaping,
  regular expressions, and a uniform interface to three C libraries
  (PCRE, RE2, ICU). We describe the main features of \pkg{nc}, then
  provide detailed comparisons with related R packages (\pkg{stats},
  \pkg{utils}, \pkg{data.table}, \pkg{tidyr}, \pkg{reshape2},
  \pkg{cdata}).}

\section{Introduction}

Regular expressions are powerful tools for text processing that are
available in many programming languages, including R. A regular
expression \dfn{pattern} defines a set of \dfn{matches} in a
\dfn{subject} string. For example, the pattern \code{.*[.].*} matches
zero or more non-newline characters, followed by a period, followed by
zero or more non-newline characters. It would match the subjects
\code{Sepal.Length} and \code{Petal.Width}, but it would not match in
the subject \code{Species}.

The focus of this article is patterns with capture groups, which are
typically defined using parentheses. For example, the pattern
\code{(.*)[.](.*)} results in the same matches as the pattern in the
previous paragraph, and it additionally allows the user to capture and
extract the substrings by group index (e.g. group 1 matches
\code{Sepal}, group 2 matches \code{Length}).

Named capture groups allow extracting the a substring by name rather
than by index. Using names rather than indices is useful in order to
create more readable regular expressions (names document the purpose
of each sub-pattern), and to create more readable \R\ code (it is
easier to understand the intent of named references than numbered
references). For example, the pattern
\code{(?<part>.*)[.](?<dimension>.*)} documents that the flower part
appears before the measurement dimension; the \code{part} group
matches \code{Sepal} and the \code{dimension} group matches
\code{Length}.

Recently, \citet{HOCKING2019-namedCapture} proposed a new syntax for
defining named capture groups in R code. Using this new syntax,
named capture groups are specified using named arguments in R,
which results in code that is easier to read and modify than
capture groups defined in string literals. For example, the
pattern in the previous paragraph can be written as \code{part=".*",}
\code{"[.]",} \code{dimension=".*"}.
Sub-patterns can be grouped for
clarity and/or re-used using
lists, and numeric data may be extracted by specifying group-specific
type conversion functions.

A main thesis of this article is that regular expressions can greatly
simplify the code required to specify wide-to-tall data reshaping
operations. For one such operation the input is a ``wide'' table with
many columns, and the desired output is a ``tall'' table with more
rows, and some of the input columns converted into a smaller number of
output columns (Figure~\ref{fig:wide-to-tall}). To clarify the
discussion we first define three terms that we will use to refer to
the different types of columns involved in this conversion:
\begin{description}
\item[Reshape] columns contain the data which is present in the same
  amount but in different shapes in the input and output. There are
  equivalent terms used in different R packages: \code{varying} in
  \code{utils::reshape}, \code{measure.vars} in \code{melt}
  (\pkg{data.table}, \pkg{reshape2}), etc.
\item[Copy] columns contain data in the input which are each copied to
  multiple rows in the output (\code{id.vars} in \code{melt}).
\item[Capture] columns are only present in the output, and contain
  data which come from matching a
  capturing regex pattern to the input reshape column names.
\end{description}
For example the wide iris data (W in Figure~\ref{fig:wide-to-tall})
have four numeric columns to reshape: \code{Sepal.Length},
\code{Sepal.Width}, \code{Petal.Length}, \code{Petal.Width}. For some
purposes (e.g. displaying a histogram of each reshape input column
using facets in \CRANpkg{ggplot2}) the desired reshaping operation
results in a table with a single reshape output column (S in
Figure~\ref{fig:wide-to-tall}), two copied columns, and two columns
captured from the names of the reshaped input columns. For other
purposes (e.g. scatterplot to compare Petal and Sepal sizes) the
desired reshaping operation results in a table with multiple reshape
output columns (M1 with \code{Sepal} and \code{Petal} columns in
Figure~\ref{fig:wide-to-tall}), two copied columns, and one column
captured from the names of the reshaped input columns. We propose to
use the new regular expression syntax of
\citet{HOCKING2019-namedCapture}, e.g. \code{part=".*",} \code{"[.]",}
\code{dimension=".*"}, to define both types of wide-to-tall data
reshaping operations. In particular, we propose using a single
capturing regular expression for defining both (1) the subset of
reshape input columns to convert, and (2) the additional capture
output columns. We will show that this results in a simple, powerful,
non-repetitive syntax for wide-to-tall data reshaping.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figure-1-iris}
  \caption{Two rows of the iris data set (W, black) are considered as
    the input to a wide-to-tall reshape operation. Four input reshape
    columns are converted to either a single output reshape column (S,
    blue) or multiple (2) output reshape columns (M1, M2, red). Other
    output columns are either copied from the non-reshaped input data,
    or captured from the names of the reshaped input columns.}
  \label{fig:wide-to-tall}
\end{figure}

In this article our original contribution is the \R\ package
\CRANpkg{nc} which provides a new implementation of the previously
proposed named capture regex syntax of
\citet{HOCKING2019-namedCapture}, in addition to several new functions
that perform wide-to-tall data reshaping using regular
expressions. The main new ideas are (1) using un-named capture groups
in the regex string literal to provide a uniform interface to three
regex C libraries, (2) integration of capture groups and
\CRANpkg{data.table} functionality \citep{Dowle2019}, and (3)
specifying wide-to-tall reshape operations with a concise syntax which
results in less repetitive user code than other packages. A secondary
contribution of this article is a detailed comparison of current R
functions for reshaping data with regular expressions.

The organization of this article is as follows. The rest of this
introduction provides an overview of current \R\ packages for regular
expressions and data reshaping. The second section describes the
proposed functions of the \CRANpkg{nc} package. The third section provides
detailed comparisons with other \R\ packages, in terms of syntax and
computation times. The article concludes with a summary and
discussion.

\section{Related work}

There are many R functions which can extract tables from non-tabular
text using regular expressions. Recommended R package functions include \code{base::regexpr}
and \code{base::gregexpr} as well as \code{utils::strcapture}. CRAN
packages include
\CRANpkg{namedCapture} \citep{namedCapture},
\CRANpkg{rematch2} \citep{rematch2},
\CRANpkg{rex} \citep{rex},
\CRANpkg{stringr} \citep{stringr},
\CRANpkg{stringi} \citep{stringi},
\CRANpkg{tidyr} \citep{tidyr},
and
\CRANpkg{re2r} \citep{re2r}.
\citet{HOCKING2019-namedCapture} provides a detailed comparison of these packages
in terms of features, syntax, and computation time.

For reshaping data from wide (one row with many columns) to tall (one
column with many rows), there are several different R functions that
provide similar functionality. Each function supports a different set
of features (Table~\ref{tab:features}); each feature/column is
explained in detail below:
\begin{description}
\item[single] refers to support for converting input reshape columns
  of the same type to a single reshape output column.
\item[multiple] refers to support for converting input reshape columns of
  possibly different types to multiple output reshape columns; ``sorted''
  means that conversion works correctly only if the input reshape columns are sorted
  in a regular order, e.g. \code{Sepal.Length}, \code{Sepal.Width},
  \code{Petal.Length}, \code{Petal.Width}; ``unsorted'' means that
  conversion works correctly even if the they are not sorted,
  e.g. \code{Sepal.Length}, \code{Sepal.Width}, \code{Petal.Width},
  \code{Petal.Length}.
\item[regex] refers to support for regular expressions; ``match''
  means a pattern is used to match the input column names; ``capture''
  means that the specified pattern is used to
  create new output capture columns --- this is especially useful when the names
  consist of several distinct pieces of information, e.g. \code{Sepal.Length};
  ``no'' means that regular expressions are not directly supported
  (although \code{base::grep} can always be used).
\item[na.rm] refers to support for removing missing values.
\item[types] refers to support for converting captured text to numeric
  output columns.
\item[list] refers to support for output of list columns.
\end{description}


\begin{table}
  \centering
  \begin{tabular}{llllllll}
\toprule
\code{pkg::function} & single & multiple & regex & na.rm & types & list \\
\midrule
\code{nc::capture\_melt\_multiple} & no & unsorted & capture & yes & any & yes\\
\code{nc::capture\_melt\_single} & yes & no & capture & yes & any & yes\\
\code{tidyr::pivot\_longer} & yes & unsorted & capture & yes & some & yes\\
\code{stats::reshape} & yes & sorted & capture & no & some & no\\
\code{data.table::melt}, \code{patterns} & yes & sorted & match & yes & no & yes\\
\code{tidyr::gather} & yes & no & no & yes & some & yes\\
\code{reshape2::melt} & yes & no & no & yes & no & no\\
\code{cdata::rowrecs\_to\_blocks} & yes & unsorted & no & no &no & yes\\
\code{cdata::unpivot\_to\_blocks} & yes & no & no & no &no & yes\\
\code{utils::stack} & yes & no & no & no & no & no\\
\bottomrule
    \end{tabular}
    \caption{\label{tab:features}
      Reshaping functions in R support various features:
      ``single'' for converting input columns into a single output column;
      ``multiple'' for converting input columns
      (either ``sorted'' in a regular order, or ``unsorted'' for any order)
      into multiple output columns of different types;
      ``regex'' for regular expressions to
      ``match'' input column names or to
      ``capture'' and create new output column names;
      ``na.rm'' for removal of missing values;
      ``types'' for converting input column names to non-character output columns;
      ``list'' for output of list columns.
    }
\end{table}

Recommended R package functions include \code{stats::reshape} and
\code{utils::stack} for reshaping data from wide to tall. Of the
features listed in Table~\ref{tab:features}, \code{utils::stack} only
supports output with a single reshape column, whereas \code{stats::reshape} supports
the following features. For data with regular input column names (output
column, separator, time value), regular expressions can be used to
specify the separator (e.g. in \code{Sepal.Length}, \code{Sepal} is
output column, dot is separator, \code{Length} is time
value). Multiple output columns are supported, but incorrect output
may be computed if input columns are not sorted in a regular
order. The time value is output to a capture column named
\code{time} by default. Automatic type conversion is performed on time values
when possible, but custom type conversion functions are not
supported. There is neither support for missing value removal nor list
column output.

The \pkg{tidyr} package provides two functions for reshaping data from
wide to tall format: \code{gather} and \code{pivot\_longer}. The older
\code{gather} function only supports converting input reshape columns to a
single output reshape column (not multiple).
The input reshape columns to convert may
not be directly specified using regular expressions; instead R
expressions such as \code{x:y} can be used to indicate all columns
starting from \code{x} and ending with \code{y}. It does support
limited type conversion; if the \code{convert=TRUE} argument is
specified, the \code{utils::type.convert} function is used to convert
the input column names to numeric, integer, or logical. In contrast
the newer \code{pivot\_longer} also supports multiple output reshape columns
(even if input reshape columns are unsorted), and regular expressions for
specifying output capture columns
(but to specify input reshape columns with a regex,
\code{grep} must be used). Limited type conversion is also supported in
\code{pivot\_longer}, via the \code{names\_ptypes} argument, which
should be a list with names corresponding to output columns and values
corresponding to prototypes (zero-length atomic vectors,
e.g. \code{numeric()}). Both functions support list columns and
removing missing values, although different arguments are used
(\code{na.rm} for \code{gather}, \code{values\_drop\_na} for
\code{pivot\_longer}).

The \CRANpkg{reshape2} and \pkg{data.table} packages each provide a
\code{melt} function for converting data from wide to tall
\citep{Wickham2007, Dowle2019}. The older \pkg{reshape2} version only
supports converting input reshape columns to a single output reshape column, whereas
the newer \pkg{data.table} version also supports multiple output reshape
columns. Regular expressions are not supported in \pkg{reshape2}, but
can be used with \code{data.table::patterns} to match input column
names to convert (although the output can be incorrect if columns are
not sorted in a regular order). Neither function supports type
conversion, and both functions support removing missing values from
the output using the \code{na.rm} argument. List column output is
supported in \pkg{data.table} but not \pkg{reshape2}.

The \CRANpkg{cdata} package provides several functions for data
reshaping, including \code{rowrecs\_to\_blocks} and
\code{unpivot\_to\_blocks} which can convert data from wide to tall
\citep{Mount2019}. The simpler of the two functions is
\code{unpivot\_to\_blocks}, which supports a single output reshape column
(interface similar to \code{reshape2::melt}/\code{tidyr::gather}). The
user of \code{rowrecs\_to\_blocks} must provide a control table that
describes how the input should be reshaped into the output. It
therefore supports multiple output reshape columns, for possibly unsorted
input columns. Both functions support list column output, but other
features from Table~\ref{tab:features} are not supported (regular
expressions, missing value removal, type conversion).

\section{New features in \pkg{nc}}

The \pkg{nc} package provides new regular expression functionality
based on the syntax recently proposed by
\citet{HOCKING2019-namedCapture}. In this section we first discuss how
the \pkg{nc} package implements this syntax as a front-end to three
regex engines, and we then discuss the new features for data reshaping
using regular expressions.

\subsection{Uniform interface to three regex engines}

Several C libraries providing regular expression engines are available
in R. The standard R distribution has included and the Perl-Compatible
Regular Expressions (PCRE) C library since 2002 \citep{R.NEWS.1.txt}.
CRAN package \pkg{re2r} provides the RE2 library, and \pkg{stringi}
provides the ICU library. Each of these regex engines has a unique
feature set, and may be preferred for different applications. For
example, PCRE is installed by default, RE2 guarantees matching in
polynomial time, and ICU provides strong unicode support. For a more
detailed comparison of the relative strengths of each regex library,
we refer the reader to the recent paper of
\citep{HOCKING2019-namedCapture}.

Each regex engine has also a different R interface, so switching from
one engine to another may require non-trivial modifications of user
code. In order to make switching between engines easier,
\citet{HOCKING2019-namedCapture} introduced the \pkg{namedCapture}
package, which provides a uniform interface for capturing text using
PCRE and RE2. The user may specify the desired engine via
e.g. \code{options(namedCapture.engine="PCRE")}; the
\pkg{namedCapture} package provides the output in a uniform
format. However \pkg{namedCapture} requires the engine to support
specifying capture group names in regex pattern strings, and to
support output of the group names to R (which ICU does not support).

Our proposed \pkg{nc} package provides support for the ICU engine in
addition to PCRE and RE2. The \pkg{nc} package implements this
functionality using un-named capture groups, which are supported in
all three regex engines. In particular, a regular expression is
constructed in R code that uses named arguments to indicate captures,
which are translated to un-named groups when passed to the regex
engine. For example, consider a user who wants to capture the two
pieces of the column names of the iris data,
e.g. \code{Sepal.Length}. The user would typically specify the
capturing regular expression as a string literal,
e.g. \code{"(.*)[.](.*)"}.
Using \pkg{nc} the same pattern can be
applied to the iris data column names via

<<capture-iris-cols>>=
nc::capture_first_vec(
  names(iris), part=".*", "[.]", dim=".*", engine="ICU", nomatch.error=FALSE)

@

Above we see an example usage of \code{nc:capture\_first\_vec}, which
is for capturing the first match of a regex from a character vector
subject (the first argument). There are a variable number of other
arguments (\code{...}) which are used to define
the regex pattern. In this case there are three pattern arguments:
\code{part=".*", "[.]", dim=".*"}. Each named R argument in the
pattern generates an un-named capture group by enclosing the specified
value in parentheses, e.g. \code{(.*)}. All of the sub-patterns are
pasted together in the sequence they appear in order to create the
final pattern that is used with the specified regex engine. The
\code{nomatch.error=FALSE} argument is given because the default is to
stop with an error if any subjects do not match the specified pattern
(the fifth subject \code{Species} does not match). Under the hood, the
following function is called to parse the pattern arguments:

<<see>>=
str(compiled <- nc::var_args_list(part=".*", "[.]", dim=".*"))

@

This function is intended mostly for internal use, but can be useful
for viewing the generated regex pattern (or using it as input to
another regex function). The return value is a named list of two
elements: \code{pattern} is the capturing regular expression which is
generated based on the input arguments, and \code{fun.list} is a named
list of type conversion functions. Group-specific type conversion functions
are useful for converting captured text into numeric output columns
\citet{HOCKING2019-namedCapture}. Note that the order of elements in
\code{fun.list} corresponds to the order of capture groups in the
pattern (e.g. first capture group named \code{part}, second
\code{dim}). These data can be used with any regex engine that
supports un-named capture groups (including ICU) in order to get a
capture matrix with column names, e.g.

<<icu>>=
m <- stringi::stri_match_first_regex(names(iris), compiled$pattern)
colnames(m) <- c("match", names(compiled$fun.list))
m

@

Again, this is not the recommended usage of \pkg{nc}, but here we give
these details in order to explain how it works. Note that the result
from \pkg{stringi} is a character matrix with three columns: first for
the entire match, and another column for each capture group. Using the
same pattern with \code{base::regexpr} (PCRE engine) or
\code{re2r::re2_match} (RE2 engine) would give slightly different
results (e.g. output when there is no match).
The \pkg{nc} package takes care of converting these different
results into a standard format which makes it easy to switch regex
engines (by changing the value of the \code{engine} argument).

Note that the standard format used by \pkg{nc}, as shown in the result
above from \code{nc::capture\_first\_vec}, is a data table. The main
reason that data tables are always output by \pkg{nc} matching functions is in
order to support numeric output columns. A secondary reason is for
the convenient syntax, as we will show in the next section.

\subsection{Data table integration and
  \code{nc::field} to avoid repetition}

In the previous section we mentioned that every \pkg{nc} matching
function outputs a data table, which can be
queried/summarized/joined/etc using a convenient syntax. In this
section we show an example of how this syntax makes is easy to parse
non-tabular text output files from a bioinformatics program.  We also
show an example of how the new \code{nc::field} function can be used
to avoid repetition when defining a pattern to match fields of the
form \code{variable=value}.

We consider a bioinformatics program called SweeD which outputs two
data files that are linked by an integer alignment ID number
\citep{SweeD}. The ``Report'' file is similar to tab-separated values
(TSV), except that there are some blank lines, followed by two forward
slashes, followed by the integer alignment number. For example, the
first few lines of the first two alignments look like:

<<sweedReport>>=
report.txt.gz <- system.file("extdata", "SweeD_Report.txt.gz", package="nc")
report.vec <- readLines(report.txt.gz)
cat(report.vec[1:5], sep="\n")
cat(report.vec[1003:1008], sep="\n")

@

The file above can be easily parsed by \code{nc::capture\_all\_str},
which is for finding all matches of a regular expression in a
multi-line text file:

<<parseReport>>=
report.alignments <- nc::capture_all_str(
  report.vec,
  "//",
  Alignment="[0-9]+",
  TSV="[^/]+")
class(report.alignments)
dim(report.alignments)
nchar(report.alignments$TSV)
substr(as.matrix(report.alignments[1:2]), 1, 50)

@

The code above computes a data table with ten rows, one for each match
in the text file. There are two columns: \code{Alignment} is a unique
identifier, and \code{TSV} contains the tab-separated values in each
block. Each \code{TSV} entry is a long text string (about 40,000
characters); we display the first 50 characters of the first two
blocks above. Because the result is a data table, we can parse the
\code{TSV} using a call to \code{fread} inside of a \code{by} block:

<<freadby>>=
(report.positions <- report.alignments[, data.table::fread(text=TSV), by=Alignment])
@

A bioinformatics analyst may desire to plot the \code{Likelihood} or
\code{Alpha} values in a genome browser, as a function of
\code{Position} along the chromosome. Each alignment has a chromosome
name which therefore needs to be added/joined to this table; the
second ``Info'' file has the chromosome name, as well as some other
summary statistics for each alignment:

<<info>>=
info.txt.gz <- system.file("extdata", "SweeD_Info.txt.gz", package="nc")
info.vec <- readLines(info.txt.gz)
info.vec[24:40]
@

Again, the data above can be parsed to a data table via a regular
expression:

<<infoparsed>>=
nc::capture_all_str(
  info.vec,
  " ",
  "Alignment", " ", Alignment="[0-9]+",
  "\n\n\t\t",
  "Chromosome", ":\t\t", Chromosome=".*")
@

The result above is a data table with ten rows, one for each
alignment. There are two columns: the first is the \code{Alignment}
identifier, and the second is the \code{Chromosome} name. Note the
repetition in the code above: \code{Alignment}/\code{Chromosome}
appear as capture group names as well as in the pattern
itself. Such repetition can be avoided by using the \code{nc::field} helper
function, which uses its first argument for the capture group name as
well as a pattern to match:

<<infoparsedfield>>=
(info.alignments <- nc::capture_all_str(
  info.vec,
  " ",
  nc::field("Alignment", " ", "[0-9]+"),
  "\n\n\t\t",
  nc::field("Chromosome", ":\t\t", ".*")))

@

Note that the repetition in the code has been removed, and the result
is the same (because the generated regex pattern is the same). Also
note that the order of the regex string literals is unchanged, so the
pattern is as easy to read/understand as the original repetitive
version. Internally, \code{nc::field} generates a pattern that
consists of pasting all of its arguments together; the first argument
is also used as the capture group name for the third (and subsequent)
arguments. In general, \code{nc::field} is useful whenever there are
several fields to parse, each of the form \code{variable=value}.

In order to create the desired output table with \code{Chromosome} and
\code{Position} columns, we join the two data tables:

<<join>>=
info.alignments[report.positions, on="Alignment"]
@

To conclude this section, we have shown that
\code{nc::capture\_all\_str} inputs a multi-line text file subject,
then outputs a data table with one row per match and one column per
capture group. We have also shown how these data tables may be further
processed (e.g. \code{fread}, \code{by=Alignment}) and joined using
the convenient data table syntax. Finally, we showed two examples of
using \code{nc::field} to define a pattern that matches/captures
fields of the form \code{variable=value}.

\subsection{Wide-to-tall data reshaping}

In this section we show how new \pkg{nc} functions can be used to
reshape wide data (with many columns) to tall data (with fewer
columns, and more rows). We begin by considering the two data
visualization problems mentioned in the introduction, involving the
familiar iris data set. First, suppose we would like to examine the
largest/smallest values or ranges. One way would be to use a histogram
of each numeric variable, with row facets for flower part and column
facets for measurement dimension. Our desired output therefore needs a
single column with all of the reshaped numeric data to plot
(Figure~\ref{fig:wide-to-tall}, W$\rightarrow$S). We can perform this
operation using \code{nc::capture\_melt\_single}, which inputs a data
frame and a pattern describing the columns to melt:

<<irisSingle>>=
(iris.tall.single <- nc::capture_melt_single(
  iris, part=".*", "[.]", dim=".*", value.name="cm"))
@

The output above consists of one copy column (\code{Species}), two
capture columns (\code{part}, \code{dim}), and a single reshape column
(\code{cm}). The \code{value.name} argument is not considered part of
the pattern, and instead specifies the name of the output reshape
column. The desired histogram may be easily plotted using these data:

<<hist>>=
library(ggplot2)
ggplot(iris.tall.single)+facet_grid(part~dim)+
  theme_bw()+theme(panel.spacing=grid::unit(0, "lines"))+
  geom_histogram(aes(cm, fill=Species), color="black", bins=40)
@

For the second data reshaping task, suppose we want to determine
whether or not sepals are larger than petals, for each measurement
dimension and species. We could use a scatterplot of sepal versus
petal, with a facet for measurement dimension. We therefore need a
data table with two reshape output columns: a \code{Sepal} column to
plot against a \code{Petal} column (Figure~\ref{fig:wide-to-tall},
W$\rightarrow$M1). We can perform this operation using
\code{nc::capture\_melt\_multiple}, which inputs a data frame and a
special pattern which must contain the \code{column} group and one
other named group:

<<irisMultiple>>=
(iris.parts <- nc::capture_melt_multiple(
  iris, column=".*", "[.]", dim=".*"))
@

The output above consists of one copy column (\code{Species}), one
capture columns (\code{dim}), and two reshape columns (\code{Petal},
\code{Sepal}). The desired scatterplot may be easily plotted using
these data:

<<hist>>=
ggplot(iris.parts)+facet_grid(.~dim)+
  theme_bw()+theme(panel.spacing=grid::unit(0, "lines"), legend.position="bottom")+
  coord_equal()+geom_abline(slope=1, intercept=0, color="grey")+
  geom_point(aes(Petal, Sepal, color=Species), shape=1)
@

It is clear from the plot that sepals are larger than petals, for
both dimensions, and for every measured flower.

As a final example we consider a data set from the World Health Organization:

<<who>>=
data(who, package="tidyr")
names(who)
tail(who[, c("country", "year", "new_sp_m014", "new_sn_f5564", "newrel_f65")])

@

Each reshape column name has three distinct pieces of information:
diagnosis type, gender, and age group.
As with the iris data, there are a number of interesting questions
that can be answered by first reshaping the data (e.g. which age
groups and diagnosis types are the most frequent).

<<whoreshape>>=
new.diag.gender <- list(
  "new_?",
  diagnosis=".*",
  "_",
  gender=".")
nc::capture_melt_single(who, new.diag.gender, ages=".*")
years.pattern <- list(new.diag.gender, ages=list(
  min.years="0|[0-9]{2}", as.numeric,
  max.years="[0-9]{0,2}", function(x)ifelse(x=="", Inf, as.numeric(x))))
(who.typed <- nc::capture_melt_single(
  who, years.pattern,
  value.name="count"))
str(who.typed)
@

\section{Comparison with other packages}

TODO

\section{Discussion and conclusions}

TODO

\paragraph{Reproducible research statement.} The source code for this
article can be freely downloaded from
\url{https://github.com/tdhock/nc-article}

\bibliography{hocking}

\address{Toby Dylan Hocking\\
  School of Informatics, Computing, and Cyber Systems\\
  Northern Arizona University\\
  Flagstaff, Arizona\\
  USA\\
  \email{toby.hocking@nau.edu}}

