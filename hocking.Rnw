\newcommand{\sectiontidyr}{Comparisons with other functions for data frames}
\newcommand{\sectiontrackDb}{Capturing all matches from a multi-line text file}
\newcommand{\sectiontimings}{Comparing computation times of R regex packages}
\newcommand{\sectiondf}{Creating new columns from character columns in a data frame}
\newcommand{\sectionrex}{Comparing \pkg{namedCapture} variable argument syntax with \pkg{rex}}
\newcommand{\sectioncomparisons}{Comparisons with other R packages}

\title{Regular expressions and reshaping using data tables and the
  \pkg{nc} package}

\author{by Toby Dylan Hocking}

\maketitle

\abstract{Regular expressions are powerful tools for extracting tables
  from non-tabular text data. Capturing regular expressions that
  describe information to extract from column names can be especially
  useful when reshaping a data table from wide (one row with many
  columns) to tall (one column with many rows). We present the R
  package \pkg{nc} (short for named capture), which provides functions
  for data reshaping, regular expressions, and a uniform interface to
  three C libraries (PCRE, RE2, ICU). We describe the main features of
  \pkg{nc}, then provide detailed comparisons with related R packages
  (\pkg{stats}, \pkg{utils}, \pkg{data.table}, \pkg{tidyr},
  \pkg{reshape2}, \pkg{cdata}).}

\section{Introduction}

Regular expressions are powerful tools for text processing that are
available in many programming languages, including R. A regular
expression \dfn{pattern} defines a set of \dfn{matches} in a
\dfn{subject} string. For example, the pattern \code{.*[.].*} matches
zero or more non-newline characters, followed by a period, followed by
zero or more non-newline characters. It would match the subjects
\code{Sepal.Length} and \code{Petal.Width}, but it would not match in
the subject \code{Species}.

The focus of this article is patterns with capture groups, which are
typically defined using parentheses. For example, the pattern
\code{(.*)[.](.*)} results in the same matches as the pattern in the
previous paragraph, and it additionally allows the user to capture and
extract the substrings by group index (e.g. group 1 matches
\code{Sepal}, group 2 matches \code{Length}).

Named capture groups allow extracting the a substring by name rather
than by index. Using names rather than indices is useful in order to
create more readable regular expressions (names document the purpose
of each sub-pattern), and to create more readable \R\ code (it is
easier to understand the intent of named references than numbered
references). For example, the pattern
\code{(?<part>.*)[.](?<dimension>.*)} documents that the flower part
appears before the measurement dimension; the \code{part} group
matches \code{Sepal} and the \code{dimension} group matches
\code{Length}.

Recently, \citet{HOCKING2019-namedCapture} proposed a new syntax for
defining named capture groups in R code. Using this new syntax,
named capture groups are specified using named arguments in R,
which results in code that is easier to read and modify than
capture groups defined in string literals. For example, the
pattern in the previous paragraph can be written as \code{part = ".*",}
\code{"[.]",} \code{dimension = ".*"}.
Sub-patterns can be grouped for
clarity and/or re-used using
lists, and numeric data may be extracted with user-provided
type conversion functions.

A main thesis of this article is that regular expressions can greatly
simplify the code required to specify wide-to-tall data reshaping
operations. For one such operation the input is a ``wide'' table with
many columns, and the desired output is a ``tall'' table with more
rows, and some of the input columns converted into a smaller number of
output columns (Figure~\ref{fig:wide-to-tall}). To clarify the
discussion we first define three terms that we will use to refer to
the different types of columns involved in this conversion:
\begin{description}
\item[Reshape] columns contain the data which is present in the same
  amount but in different shapes in the input and output. There are
  equivalent terms used in different R packages: \code{varying} in
  \code{utils::reshape}, \code{measure.vars} in \code{melt}
  (\pkg{data.table}, \pkg{reshape2}), etc.
\item[Copy] columns contain data in the input which are each copied to
  multiple rows in the output (\code{id.vars} in \code{melt}).
\item[Capture] columns are only present in the output, and contain
  data which come from matching a
  capturing regex pattern to the input reshape column names.
\end{description}
For example the wide iris data (W in Figure~\ref{fig:wide-to-tall})
have four numeric columns to reshape: \code{Sepal.Length},
\code{Sepal.Width}, \code{Petal.Length}, \code{Petal.Width}. For some
purposes (e.g. displaying a histogram of each reshape input column
using facets in \CRANpkg{ggplot2}) the desired reshaping operation
results in a table with a single reshape output column (S in
Figure~\ref{fig:wide-to-tall}), two copied columns, and two columns
captured from the names of the reshaped input columns. For other
purposes (e.g. scatterplot to compare sepal and petal sizes) the
desired reshaping operation results in a table with multiple reshape
output columns (M1 with \code{Sepal} and \code{Petal} columns in
Figure~\ref{fig:wide-to-tall}), two copied columns, and one column
captured from the names of the reshaped input columns. We propose to
use the new regular expression syntax of
\citet{HOCKING2019-namedCapture}, e.g. \code{part = ".*",} \code{"[.]",}
\code{dimension = ".*"}, to define both types of wide-to-tall data
reshaping operations. In particular, we propose using a single
capturing regular expression for defining both (1) the subset of
reshape input columns to convert, and (2) the additional capture
output columns. We will show that this results in a simple, powerful,
non-repetitive syntax for wide-to-tall data reshaping.

\begin{figure}
  \centering
  \includegraphics[width = 0.9\textwidth]{figure-1-iris}
  \caption{Two rows of the iris data set (W, black) are considered as
    the input to a wide-to-tall reshape operation. Four input reshape
    columns are converted to either a single output reshape column (S,
    blue) or multiple (2) output reshape columns (M1, M2, red). Other
    output columns are either copied from the non-reshaped input data,
    or captured from the names of the reshaped input columns.}
  \label{fig:wide-to-tall}
\end{figure}

In this article our original contribution is the \R\ package
\CRANpkg{nc} which provides a new implementation of the previously
proposed named capture regex syntax of
\citet{HOCKING2019-namedCapture}, in addition to several new functions
that perform wide-to-tall data reshaping using regular
expressions. The main new ideas are (1) using un-named capture groups
in the regex pattern string to provide a uniform interface to three
regex C libraries, (2) integration of \CRANpkg{data.table}
functionality \citep{Dowle2019}, and (3) specifying wide-to-tall
reshape operations with a concise syntax which results in less
repetitive user code than other packages. A secondary contribution of
this article is a detailed comparison of current R functions for
reshaping data, in terms of syntax, computation times, and
functionality (Table~\ref{tab:features}).

The organization of this article is as follows. The rest of this
introduction provides an overview of current \R\ packages for regular
expressions and data reshaping. The second section describes the
proposed functions of the \CRANpkg{nc} package, then the third section
provides detailed comparisons with other \R\ packages. The article
concludes with a summary and discussion.

\section{Related work}

There are many R functions which can extract tables from non-tabular
text using regular expressions. Recommended R package functions
include \code{base::regexpr} and \code{base::gregexpr} as well as
\code{utils::strcapture}. CRAN packages which provide various
functions for text processing using regular expressions include
\CRANpkg{namedCapture} \citep{namedCapture}, \CRANpkg{rematch2}
\citep{rematch2}, \CRANpkg{rex} \citep{rex}, \CRANpkg{stringr}
\citep{stringr}, \CRANpkg{stringi} \citep{stringi}, \CRANpkg{tidyr}
\citep{tidyr}, and \CRANpkg{re2r} \citep{re2r}.  We refer the reader
to our previous research paper for a detailed comparison of these
packages \citep{HOCKING2019-namedCapture}.

For reshaping data from wide (one row with many columns) to tall (one
column with many rows), there are several different R functions that
provide similar functionality. Each function supports a different set
of features (Table~\ref{tab:features}); each feature/column is
explained in detail below:
\begin{description}
\item[single] refers to support for converting input reshape columns
  of the same type to a single reshape output column.
\item[multiple] refers to support for converting input reshape columns of
  possibly different types to multiple output reshape columns; ``sorted''
  means that conversion works correctly only if the input reshape columns are sorted
  in a regular order, e.g. \code{Sepal.Length}, \code{Sepal.Width},
  \code{Petal.Length}, \code{Petal.Width}; ``unsorted'' means that
  conversion works correctly even if the they are not sorted,
  e.g. \code{Sepal.Length}, \code{Sepal.Width}, \code{Petal.Width},
  \code{Petal.Length}.
\item[regex] refers to support for regular expressions; ``match''
  means a pattern is used to match the input column names; ``capture''
  means that the specified pattern is used to
  create new output capture columns --- this is especially useful when the names
  consist of several distinct pieces of information, e.g. \code{Sepal.Length};
  ``no'' means that regular expressions are not directly supported
  (although \code{base::grep} can always be used).
\item[na.rm] refers to support for removing missing values.
\item[types] refers to support for converting captured text to numeric
  output columns.
\item[list] refers to support for output of list columns.
\end{description}


\begin{table}
  \centering
  \begin{tabular}{llllllll}
\toprule
\code{pkg::function} & single & multiple & regex & na.rm & types & list \\
\midrule
\code{nc::capture\_melt\_multiple} & no & unsorted & capture & yes & any & yes\\
\code{nc::capture\_melt\_single} & yes & no & capture & yes & any & yes\\
\code{tidyr::pivot\_longer} & yes & unsorted & capture & yes & some & yes\\
\code{stats::reshape} & yes & sorted & capture & no & some & no\\
\code{data.table::melt}, \code{patterns} & yes & sorted & match & yes & no & yes\\
\code{tidyr::gather} & yes & no & no & yes & some & yes\\
\code{reshape2::melt} & yes & no & no & yes & no & no\\
\code{cdata::rowrecs\_to\_blocks} & yes & unsorted & no & no &no & yes\\
\code{cdata::unpivot\_to\_blocks} & yes & no & no & no &no & yes\\
\code{utils::stack} & yes & no & no & no & no & no\\
\bottomrule
    \end{tabular}
    \caption{\label{tab:features}
      Reshaping functions in R support various features:
      ``single'' for converting input columns into a single output column;
      ``multiple'' for converting input columns
      (either ``sorted'' in a regular order, or ``unsorted'' for any order)
      into multiple output columns of different types;
      ``regex'' for regular expressions to
      ``match'' input column names or to
      ``capture'' and create new output column names;
      ``na.rm'' for removal of missing values;
      ``types'' for converting input column names to non-character output columns;
      ``list'' for output of list columns.
    }
\end{table}

Recommended R package functions include \code{stats::reshape} and
\code{utils::stack} for reshaping data from wide to tall. Of the
features listed in Table~\ref{tab:features}, \code{utils::stack} only
supports output with a single reshape column, whereas \code{stats::reshape} supports
the following features. For data with regular input column names (output
column, separator, time value), regular expressions can be used to
specify the separator (e.g. in \code{Sepal.Length}, \code{Sepal} is
output column, dot is separator, \code{Length} is time
value). Multiple output columns are supported, but incorrect output
may be computed if input columns are not sorted in a regular
order. The time value is output to a capture column named
\code{time} by default. Automatic type conversion is performed on time values
when possible, but custom type conversion functions are not
supported. There is neither support for missing value removal nor list
column output.

The \pkg{tidyr} package provides two functions for reshaping data from
wide to tall format: \code{gather} and \code{pivot\_longer}. The older
\code{gather} function only supports converting input reshape columns to a
single output reshape column (not multiple).
The input reshape columns to convert may
not be directly specified using regular expressions; instead R
expressions such as \code{x:y} can be used to indicate all columns
starting from \code{x} and ending with \code{y}. It does support
limited type conversion; if the \code{convert = TRUE} argument is
specified, the \code{utils::type.convert} function is used to convert
the input column names to numeric, integer, or logical. In contrast
the newer \code{pivot\_longer} also supports multiple output reshape columns
(even if input reshape columns are unsorted), and regular expressions for
specifying output capture columns
(but to specify input reshape columns with a regex,
\code{grep} must be used). Limited type conversion is also supported in
\code{pivot\_longer}, via the \code{names\_ptypes} argument, which
should be a list with names corresponding to output columns and values
corresponding to prototypes (zero-length atomic vectors,
e.g. \code{numeric()}). Both functions support list columns and
removing missing values, although different arguments are used
(\code{na.rm} for \code{gather}, \code{values\_drop\_na} for
\code{pivot\_longer}).

The \CRANpkg{reshape2} and \pkg{data.table} packages each provide a
\code{melt} function for converting data from wide to tall
\citep{Wickham2007, Dowle2019}. The older \pkg{reshape2} version only
supports converting input reshape columns to a single output reshape column, whereas
the newer \pkg{data.table} version also supports multiple output reshape
columns. Regular expressions are not supported in \pkg{reshape2}, but
can be used with \code{data.table::patterns} to match input column
names to convert (although the output can be incorrect if columns are
not sorted in a regular order). Neither function supports type
conversion, and both functions support removing missing values from
the output using the \code{na.rm} argument. List column output is
supported in \pkg{data.table} but not \pkg{reshape2}.

The \CRANpkg{cdata} package provides several functions for data
reshaping, including \code{rowrecs\_to\_blocks} and
\code{unpivot\_to\_blocks} which can convert data from wide to tall
\citep{Mount2019}. The simpler of the two functions is
\code{unpivot\_to\_blocks}, which supports a single output reshape column
(interface similar to \code{reshape2::melt}/\code{tidyr::gather}). The
user of \code{rowrecs\_to\_blocks} must provide a control table that
describes how the input should be reshaped into the output. It
therefore supports multiple output reshape columns, for possibly unsorted
input columns. Both functions support list column output, but other
features from Table~\ref{tab:features} are not supported (regular
expressions, missing value removal, type conversion).

\section{New features in \pkg{nc} for regular expressions and data reshaping}

The \pkg{nc} package provides new regular expression functionality
based on the syntax recently proposed by
\citet{HOCKING2019-namedCapture}. In this section we first discuss how
the \pkg{nc} package implements this syntax as a front-end to three
regex engines, and we then discuss the new features for data reshaping
using regular expressions.

\subsection{Uniform interface to three regex engines}

Several C libraries providing regular expression engines are available
in R. The standard R distribution has included and the Perl-Compatible
Regular Expressions (PCRE) C library since 2002 \citep{R.NEWS.1.txt}.
CRAN package \pkg{re2r} provides the RE2 library, and \pkg{stringi}
provides the ICU library. Each of these regex engines has a unique
feature set, and may be preferred for different applications. For
example, PCRE is installed by default, RE2 guarantees matching in
polynomial time, and ICU provides strong unicode support. For a more
detailed comparison of the relative strengths of each regex library,
we refer the reader to our previous research paper
\citep{HOCKING2019-namedCapture}.

Each regex engine has a different R interface, so switching from
one engine to another may require non-trivial modifications of user
code. In order to make switching between engines easier,
\citet{HOCKING2019-namedCapture} introduced the \pkg{namedCapture}
package, which provides a uniform interface for capturing text using
PCRE and RE2. The user may specify the desired engine via
an option; the
\pkg{namedCapture} package provides the output in a uniform
format. However \pkg{namedCapture} requires the engine to support
specifying capture group names in regex pattern strings, and to
support output of the group names to R (which ICU does not support).

Our proposed \pkg{nc} package provides support for the ICU engine in
addition to PCRE and RE2. The \pkg{nc} package implements this
functionality using un-named capture groups, which are supported in
all three regex engines. In particular, a regular expression is
constructed in R code that uses named arguments to indicate capturing
sub-patterns, which are translated to un-named groups when passed to
the regex engine. For example, consider a user who wants to capture
the two pieces of the column names of the iris data,
e.g. \code{Sepal.Length}. The user would typically specify the
capturing regular expression as a string literal,
e.g. \code{"(.*)[.](.*)"}.  Using \pkg{nc} the same pattern can be
applied to the iris data column names via

<<capture-iris-cols>>= 
nc::capture_first_vec(
  names(iris), part = ".*", "[.]", dim = ".*", engine = "ICU", nomatch.error = FALSE)

@

Above we see an example usage of \code{nc:capture\_first\_vec}, which
is for capturing the first match of a regex from a character vector
subject (the first argument). There are a variable number of other
arguments (\code{...}) which are used to define
the regex pattern. In this case there are three pattern arguments:
\code{part = ".*", "[.]", dim = ".*"}. Each named R argument in the
pattern generates an un-named capture group by enclosing the specified
value in parentheses, e.g. \code{(.*)}. All of the sub-patterns are
pasted together in the sequence they appear in order to create the
final pattern that is used with the specified regex engine. The
\code{nomatch.error = FALSE} argument is given because the default is to
stop with an error if any subjects do not match the specified pattern
(the fifth subject \code{Species} does not match). Under the hood, the
following function is called to parse the pattern arguments:

<<see>>= 
str(compiled <- nc::var_args_list(part = ".*", "[.]", dim = ".*"))

@

This function is intended mostly for internal use, but can be useful
for viewing the generated regex pattern (or using it as input to
another regex function). The return value is a named list of two
elements: \code{pattern} is the capturing regular expression which is
generated based on the input arguments, and \code{fun.list} is a named
list of type conversion functions. Group-specific type conversion functions
are useful for converting captured text into numeric output columns
\citep{HOCKING2019-namedCapture}. Note that the order of elements in
\code{fun.list} corresponds to the order of capture groups in the
pattern (e.g. first capture group named \code{part}, second
\code{dim}). These data can be used with any regex engine that
supports un-named capture groups (including ICU) in order to get a
capture matrix with column names, e.g.

<<icu>>= 
m <- stringi::stri_match_first_regex(names(iris), compiled$pattern)
colnames(m) <- c("match", names(compiled$fun.list))
m

@

Again, this is not the recommended usage of \pkg{nc}, but here we give
these details in order to explain how it works. Note that the result
from \pkg{stringi} is a character matrix with three columns: first for
the entire match, and another column for each capture group. Using the
same pattern with \code{base::regexpr} (PCRE engine) or
\code{re2r::re2\_match} (RE2 engine) yields output in varying formats.
The \pkg{nc} package takes care of converting these different results
into a standard format which makes it easy to switch regex engines (by
changing the value of the \code{engine} argument).

Note that the standard format used by \pkg{nc}, as shown above with
\code{nc::capture\_first\_vec}, is a data table. The main reason that
data tables are always output by \pkg{nc} matching functions is in
order to support numeric output columns, when type conversion
functions are specified. A secondary reason is for the convenient
syntax, as we will show in the next section.

\subsection{Data table integration and
  \code{nc::field} to avoid repetition}

In the previous section we mentioned that every \pkg{nc} matching
function outputs a data table, which can be
queried/summarized/joined/etc using the convenient syntax of the
\pkg{data.table} package. In this section we show an example of how
this syntax makes is easy to parse non-tabular text output files from
a bioinformatics program.  We also show an example of how the new
\code{nc::field} function can be used to avoid repetition when
defining a pattern to match fields of the form \code{variable = value}.

We consider a bioinformatics program called SweeD which outputs two
data files that are linked by an integer alignment ID number
\citep{SweeD}. The ``Report'' file is similar to tab-separated values
(TSV), except that there are some blank lines, followed by two forward
slashes, followed by the integer alignment number. For example, the
first few lines of the first two alignments look like:

<<sweedReport>>= 
report.txt.gz <- system.file("extdata", "SweeD_Report.txt.gz", package = "nc")
report.vec <- readLines(report.txt.gz)
cat(report.vec[1:5], sep = "\n")
cat(report.vec[1003:1008], sep = "\n")

@

The file above can be easily parsed by \code{nc::capture\_all\_str},
which is for finding all matches of a regular expression in a
multi-line text file:
nn
<<parseReport>>= 
report.alignments <- nc::capture_all_str(
  report.vec, "//", Alignment = "[0-9]+", TSV = "[^/]+")
class(report.alignments)
dim(report.alignments)
nchar(report.alignments$TSV)
substr(as.matrix(report.alignments[1:2]), 1, 50)

@

The code above computes a data table with ten rows, one for each match
in the text file. There are two columns: \code{Alignment} is a unique
identifier, and \code{TSV} contains the tab-separated values in each
block. Each \code{TSV} entry is a long text string (about 40,000
characters); we display the first 50 characters of the first two
blocks above. Because the result is a data table, we can parse the
\code{TSV} using a call to \code{fread} inside of a \code{by} block:

<<freadby>>= 
(report.positions <- report.alignments[, data.table::fread(text = TSV), by = Alignment])
@

A bioinformatics analyst may desire to plot the \code{Likelihood} or
\code{Alpha} values in a genome browser, as a function of
\code{Position} along the chromosome. Each alignment has a chromosome
name which therefore needs to be added/joined to this table; the
second ``Info'' file has the chromosome name, as well as some other
summary statistics for each alignment:

<<info>>= 
info.txt.gz <- system.file("extdata", "SweeD_Info.txt.gz", package = "nc")
info.vec <- readLines(info.txt.gz)
info.vec[24:40]
@

Again, the data above can be parsed to a data table via a regular
expression:

<<infoparsed>>= 
nc::capture_all_str(
  info.vec, " ",
  "Alignment", " ", Alignment = "[0-9]+",
  "\n\n\t\t",
  "Chromosome", ":\t\t", Chromosome = ".*")
@

The result above is a data table with ten rows, one for each
alignment. There are two columns: the first is the \code{Alignment}
identifier, and the second is the \code{Chromosome} name. Note the
repetition in the code above: \code{Alignment}/\code{Chromosome}
appear as capture group names as well as in the pattern string
literals. Such repetition can be avoided by using the \code{nc::field}
helper function, which uses its first argument for the capture group
name as well as a pattern to match:

<<infoparsedfield>>= 
(info.alignments <- nc::capture_all_str(
  info.vec, " ",
  nc::field("Alignment", " ", "[0-9]+"),
  "\n\n\t\t",
  nc::field("Chromosome", ":\t\t", ".*")))

@

Note that the repetition in the code has been removed, and the result
is the same (because the generated regex pattern is the same). Also
note that the order of the regex string literals is unchanged, so the
pattern is as easy to read/understand as the original repetitive
version. Internally, \code{nc::field} generates a pattern by
concatenating all of its arguments; the first argument is also used as
the capture group name for the third argument. In general,
\code{nc::field} is useful whenever the subject contains fields of the
form \code{variable = value}.

In order to create the desired output table with \code{Chromosome} and
\code{Position} columns, we join the two data tables:

<<join>>= 
info.alignments[report.positions, on = "Alignment"]
@

To conclude this section, we have shown that
\code{nc::capture\_all\_str} inputs a multi-line text file subject,
then outputs a data table with one row per match and one column per
capture group. We have also shown how these data tables may be further
processed (e.g. \code{fread}, \code{by = Alignment}) and joined using
the convenient data table syntax. Finally, we showed two examples of
using \code{nc::field} to define patterns that match/capture
fields of the form \code{variable = value}.

\subsection{Wide-to-tall data reshaping}

In this section we show how new \pkg{nc} functions can be used to
reshape wide data (with many columns) to tall data (with fewer
columns, and more rows). We begin by considering the two data
visualization problems mentioned in the introduction, involving the
familiar iris data set. First, suppose we would like to visualize the
univariate distribution of each numeric variable. One way would be to
use a histogram of each numeric variable, with row facets for flower
part and column facets for measurement dimension. Our desired output
therefore needs a single column with all of the reshaped numeric data
to plot (Figure~\ref{fig:wide-to-tall}, W$\rightarrow$S). We can
perform this operation using \code{nc::capture\_melt\_single}, which
inputs a data frame and a pattern describing the columns to melt:

<<irisSingle>>= 
(iris.tall.single <- nc::capture_melt_single(
  iris, part = ".*", "[.]", dim = ".*", value.name = "cm"))
@

The output above consists of one copy column (\code{Species}), two
capture columns (\code{part}, \code{dim}), and a single reshape column
(\code{cm}). The \code{value.name} argument is not considered part of
the pattern, and instead specifies the name of the output reshape
column. These data can be used to create the desired histogram with
\pkg{ggplot2} via:

<<hist, fig = TRUE, height = 2.2, width = 5>>= 
library(ggplot2)
ggplot(iris.tall.single) + facet_grid(part~dim) +
  theme_bw() + theme(panel.spacing = grid::unit(0, "lines")) +
  geom_histogram(aes(cm, fill = Species), color = "black", bins = 40)
@

For the second data reshaping task, suppose we want to determine
whether or not sepals are larger than petals, for each measurement
dimension and species. We could use a scatterplot of sepal versus
petal, with a facet for measurement dimension. We therefore need a
data table with two reshape output columns: a \code{Sepal} column to
plot against a \code{Petal} column (Figure~\ref{fig:wide-to-tall},
W$\rightarrow$M1). We can perform this operation using another
function, \code{nc::capture\_melt\_multiple}, which inputs a data
frame and a pattern which must contain the \code{column} group
and one other named group:

<<irisMultiple>>= 
(iris.parts <- nc::capture_melt_multiple(
  iris, column = ".*", "[.]", dim = ".*"))
@

The output above consists of one copy column (\code{Species}), one
capture column (\code{dim}), and two reshape columns (\code{Petal},
\code{Sepal}). Note that each unique value captured in the special
\code{column} group becomes an output reshape column
name. These data can be used to create the scatterplot using
\pkg{ggplot2} via:

<<scatter, fig = TRUE, height = 2, width = 5>>= 
ggplot(iris.parts) + facet_grid(.~dim) +
  theme_bw() + theme(panel.spacing = grid::unit(0, "lines")) +
  coord_equal() + geom_abline(slope = 1, intercept = 0, color = "grey") +
  geom_point(aes(Petal, Sepal, color = Species), shape = 1)
@

It is clear from the plot that sepals are larger than petals, for
both dimensions, and for every measured flower.

To conclude this section, \pkg{nc} provides two new functions for data
reshaping using regular expressions. Both functions input a data
frame to reshape, and a pattern to match to the column names. For
\code{nc::capture\_melt\_single}, all matching input columns are
reshaped in the output to a single column which is named using the
\code{value.name} argument. For \code{nc::capture\_melt\_multiple} the
output is multiple reshape columns with names defined by the values
captured in the special \code{column} group. Values from other
groups are stored in capture columns in the output. Both functions
support output of numeric capture columns via user-specified type
conversion functions.

\section{Comparison with other data reshaping packages}

In this section we compare the new data reshaping functions in the
\pkg{nc} package with similar functions in other packages. We aim to
demonstrate that the new \pkg{nc} syntax is often more powerful and
less repetitive.

\subsection{Advantages with respect to \pkg{tidyr}: pattern syntax and type conversion}

In terms of functionality for wide-to-tall data reshaping, the most
similar package to \pkg{nc} is \pkg{tidyr}
(Table~\ref{tab:features}). One advantage of \pkg{nc} is that complex
patterns may be defined in terms of simpler sub-patterns, which can
include group names and type conversion functions. Integrating these
three pieces results in a syntax that is easy to read as well; it is
more difficult to build and read complex patterns using \pkg{tidyr}
syntax, which requires specifying regex pattern strings, group names,
and types as separate arguments. Another advantage of \pkg{nc} is that
the range of possible type conversions for capture output columns is
essentially unlimited, since the user may provide an arbitrary type
conversion function for each group. In contrast the \pkg{tidyr} user
may specify a prototype for each group, which results in a limited
range of possible conversions. Of course, post-processing may be used,
but that introduces some repetition (of capture column names) in the
code. For example, consider a data set from the World Health
Organization (WHO):

<<who>>= 
data(who, package = "tidyr")
set.seed(1);sample(names(who), 10)

@

Each reshape column name starts with \code{new} and has three distinct
pieces of information: diagnosis type (e.g. \code{ep}, \code{rel}),
gender (\code{m} or \code{f}), and age range (e.g. \code{1524},
\code{4554}). We extract all three pieces of information below,
and include a function for converting gender to a factor with levels
in a specific (non-default) order:

<<whoreshape>>= 
nc.who.sub.pattern <- list(
  "new_?", diagnosis = ".*", "_",
  gender = ".", function(mf)factor(mf, c("m", "f")))
nc.who.ages <- nc::capture_melt_single(who, nc.who.sub.pattern, ages = ".*")
print(nc.who.ages[1:2], class = TRUE)
@

First note that \code{nc.who.sub.pattern} is a sub-pattern list variable that we
have used as the first part of the pattern in the call to
\code{nc::capture\_melt\_single} above (and we will use that
sub-pattern again below). Sub-pattern lists may contain regex
character strings (patterns to match), functions (for
converting the previous capture group), or other sub-pattern lists. The
reshaped output is a data table with \code{gender} converted to a factor ---
this can also be done using \code{tidyr::pivot\_longer}:

<<pivot>>= 
tidyr.who.sub.pattern <- "new_?(.*)_(.)"                      #L1
tidyr.who.pattern <- paste0(tidyr.who.sub.pattern, "(.*)")    #L2
tidyr::pivot_longer(                                          #L3
  who, cols = grep(tidyr.who.pattern, names(who)),            #L4
  names_to = c("diagnosis", "gender", "ages"),                #L5
  names_ptypes = list(gender = factor(levels = c("m", "f"))), #L6
  names_pattern = tidyr.who.pattern)[1:2,]                    #L7
@

In the code above we first define a sub-pattern variable for the
\code{diagnosis} and \code{gender} capture groups, as we did using
\pkg{nc}. One difference is that the \pkg{tidyr} pattern is a string
literal with un-named capture groups, whereas the \pkg{nc} pattern is
a list which includes capture group names as well as type conversion
functions. These three parameters are specified as three separate
arguments in \pkg{tidyr}, which results in some separation (e.g. group
names defined on L5 but sub-patterns are defined on L1) and repetition
(e.g. gender appears on L5 and L6) in the code. The pattern also must
be repeated: first in the \code{cols} argument (L4) to specify the set
of input reshape columns, second in the \code{names\_pattern} argument
(L7) to specify the conversion from input reshape column names to
output capture column values.

Now suppose we want to extract two numeric columns from \code{ages},
for example to use as interval-censored outputs in a survival
regression. Using \pkg{nc} we can use the previously defined
sub-pattern (including the previously defined group names and type
conversion function) as the first part of a larger pattern:

<<who2>>= 
who.typed <- nc::capture_melt_single(
  who, nc.who.sub.pattern, ages = list(
    ymin = "0|[0-9]{2}", as.numeric,
    ymax = "[0-9]{0,2}", function(x)ifelse(x == "", Inf, as.numeric(x))))
who.typed[, .(rows = .N), by = .(ages, ymin, ymax)]

@

Note in the code above that each group name, regex pattern string, and
corresponding type conversion function appears on the same line ---
this syntax keeps these three related pieces of information close
together, which makes complex patterns easier to read and build from
smaller pieces. Also, note how an anonymous function is used to
convert the values captured in the \code{ymax} group to numeric (and
it maps the empty string to \code{Inf}). Such custom type conversion
functions are not supported by \pkg{tidyr}, so post-processing must be
used:


<<idyr2>>= 
tidyr.who.pattern2 <- paste0(tidyr.who.sub.pattern, "((0|[0-9]{2})([0-9]{0,2}))")
transform(tidyr::pivot_longer(
  who, cols = grep(tidyr.who.pattern2, names(who)),
  names_to = c("diagnosis", "gender", "ages", "ymin", "ymax"),
  names_ptypes = list(gender = factor(levels = c("m", "f")), ymin = numeric()),
  names_pattern = tidyr.who.pattern2),
  ymax = ifelse(ymax == "", Inf, as.numeric(ymax)))[1:7,]
@

The code above uses \code{transform} as a post-processing step to
compute a numeric \code{ymax} column, which involves some repetition
(\code{ymax} appears four times). Note that numeric conversions which
do not require special logic (e.g. \code{ymin} above) can be specified
as prototypes using the \code{names\_ptypes} argument (but specifying
\code{ymax = numeric()} as a prototype results in a lossy cast error).

To conclude this comparison, we have seen that defining a complex
pattern is much more readable/understandable using \pkg{nc} syntax,
because it keeps group-specific names and type conversion functions
near the corresponding sub-patterns. We have also shown that
repetition is often necessary with \pkg{tidyr} (e.g. pattern, group
names), whereas such repetition can be avoided by using \pkg{nc}.

\subsection{Comparison with \pkg{data.table} and \code{stats::reshape}}

In this section we demonstrate the advantages of using \pkg{nc} over
\pkg{data.table} (which is used to implement \pkg{nc}
functionality). A major advantage is that \pkg{data.table} only
supports regular expressions for defining the set of input columns to
reshape; it does not support capture output columns. Another advantage
is that \pkg{nc} always returns a correct output data set with
multiple reshape columns, even when the input columns are not sorted
in a regular order. For example, consider the following simple data
set in which the columns are not in regular order:

<<iris2>>= 
library(data.table)
(TC <- data.table(
  treatment.age = 13,
  control.gender = "M",
  treatment.gender = "F",
  control.age = 25))
@

It is clear from the table above that the treatment group consists of
a teenage female, whereas the control group consists of a male aged 25
(not the best experimental design, but easy to remember for the
demonstration in this section). Assume we need an output data table
with two reshape columns (\code{age} and \code{gender}) as well as a
capture column (\code{group}). The \pkg{nc} syntax we would use is:

<<ncgroups>>= 
nc::capture_melt_multiple(TC, group = ".*", "[.]", column = ".*")
@

The correct result is computed above because \pkg{nc} reshapes based
on the input column names (the order of the input columns is not
relevant). A na\"ive user may attempt to perform this reshape using
\code{data.table::patterns}:

<<patterns>>= 
melt(TC, measure.vars = patterns(age = "age", gender = "gender"))
@

First, note that the syntax above requires repetition of \code{age}
and \code{gender} (in names and in pattern strings). Also it is clear
that the result is incorrect!  Actually, \code{patterns} is working as
documented; it ``returns the matching indices'' of the provided
regex. However, since the input columns are not sorted in regular
order, \code{melt} returns an incorrect result. To get a correct
result, we can provide a list of index vectors:

<<oo>>= 
melt(TC, measure.vars = list(age = c(1,4), gender = c(3,2)))
@

This is what \pkg{nc} does internally; it also converts the
\code{variable} output column to a more interpretable/useful capture
column (e.g. \code{group} above).

The \code{stats::reshape} function suffers from the same
issue. Another issue with this function is that it assumes the output
reshape column names are the first part of the input column names
(e.g. Figure~\ref{fig:wide-to-tall}, W$\rightarrow$M1). When input
column names have a different structure
(e.g. Figure~\ref{fig:wide-to-tall}, W$\rightarrow$M2), they must be
renamed, putting the desired output reshape
column names first:

<<reshapenames>>= 
TC.renamed <- structure(TC, names = sub("(.*)[.](.*)", "\\2.\\1", names(TC)))
stats::reshape(TC.renamed, 1:4, direction = "long", timevar = "group")
@

However the result above still contains incorrect results in the
\code{gender} column. The correct result can be obtained by sorting
the input column names:

<<reshapesort>>= 
TC.sorted <- data.frame(TC.renamed)[, sort(names(TC.renamed))]
stats::reshape(TC.sorted, 1:4, direction = "long", timevar = "group")
@

After renaming and sorting the input columns, the correct result is
obtained using \code{stats::reshape}. Another way to obtain a
correct result is with the \pkg{cdata} package:

<<cdata>>= 
cdata::rowrecs_to_blocks(TC, controlTable = data.frame(
  group = c("treatment", "control"),
  age = c("treatment.age", "control.age"),
  gender = c("treatment.gender", "control.gender"),
  stringsAsFactors = FALSE))
@

The \pkg{cdata} package is very powerful, and can handle many
more types of data reshaping operations than \pkg{nc}. However, it
requires a very explicit definition of the desired conversion in terms
of a control table, which results in rather verbose code. In contrast,
the terse regular expression syntax of \pkg{nc} is a more implicit
approach, which assumes the input columns to reshape have regular
names.

To conclude this section, we have discussed some advantages of
\pkg{nc} relative to other R packages. Regular expressions can be used
in \pkg{nc} to specify capture output columns, which are not provided
in the results from other functions such as
\code{data.table::melt}. Input columns with regular names do not need
to be renamed/sorted for \pkg{nc} functions, whereas renaming/sorting
may be necessary using other functions (\code{data.table::melt},
\code{stats::reshape}). Verbose/explicit control table code is always necessary
with \pkg{cdata}, whereas a terse/implicit regular expression syntax is
used with \pkg{nc} to simplify the definition of reshape operations.

\subsection{Comparing computation times}

In previous sections we have showed that the \pkg{nc} package provides
a convenient syntax for defining wide-to-tall reshape operations. In
this section we investigate whether this convenience comes at the cost
of increased computation time. We aim to demonstrate that computation
time required for the proposed \pkg{nc} package is comparable with
other packages for data reshaping. In particular, since \pkg{nc} is
implemented using \pkg{data.table}, we expect that \pkg{nc} should be
slightly slower than \pkg{data.table} (by only constant factors). For
each timing experiment we used the \CRANpkg{microbenchmark} package on
a computer with a TODO processor. We varied the number of rows/columns
in each experiment by copying/duplicating the rows/columns in each
source data set. 

First, we performed timings on a version of the WHO data with a
variable number of rows, and the original number of columns (56). As in the
previous section, we first consider a pattern with three capture
groups and no type conversions. We ran reshaping functions from
several packages (\pkg{nc}, \pkg{stats}, \pkg{utils}, \pkg{tidyr},
\pkg{reshape2}, \pkg{data.table}, \pkg{cdata}) that can compute the
desired output table with a single reshape output column. As we
expected, all functions appear to have similar asymptotic time
complexity, and differ only in terms of constant factors
(Figure~\ref{fig:timings-single-cols}, top). The slowest function was
\code{stats::reshape} (several seconds for $10^5$ rows) and the
fastest function was \code{utils::stack} (about 10 milliseconds). The
other functions, including \code{nc::capture\_melt\_single}, showed
intermediate speeds (100 to 600 milliseconds).
% > stats.timings[`capture groups`==3 & N.rows==10^5, .(N.rows, expr, median)][order(-median)]
%    N.rows                     expr     median
% 1: 100000           stats::reshape 6.23666040
% 2: 100000  nc::capture_melt_single 0.59440396
% 3: 100000      tidyr::pivot_longer 0.44018784
% 4: 100000 cdata::unpivot_to_blocks 0.40475522
% 5: 100000            tidyr::gather 0.17639912
% 6: 100000           reshape2::melt 0.09953679
% 7: 100000         data.table::melt 0.09524751
% 8: 100000             utils::stack 0.01473991

As in the previous section, we also tried using a regular expression
with five capture groups and three type conversions for capture output
columns (\code{gender} to factor, \code{ymin} and \code{ymax} to
numeric). In this test, we ran only \code{tidyr::pivot\_longer} and
\code{nc::capture\_melt\_single} because these are the only two
functions which natively support capture output columns. They both
appear to have similar asymptotic time complexity
(Figure~\ref{fig:timings-single-cols}, bottom), although
\code{nc::capture\_melt\_single} ($\text{mean}\pm\text{sd}$, $0.178\pm
0.037$ seconds for $10^5$ rows) is
about ten times faster than \code{tidyr::pivot\_longer}
($1.111\pm 0.038$).
% > stats.timings[`capture groups`==5 & N.rows==10^5, .(N.rows, expr, mean, sd)][order(-mean)]
%    N.rows                    expr      mean         sd
% 1: 100000     tidyr::pivot_longer 1.1117841 0.03833242
% 2: 100000 nc::capture_melt_single 0.1780302 0.03727452
% > 

\begin{figure}
  \centering
  \includegraphics[width = \textwidth]{figure-who-both-rows.pdf}
  \caption{Timings for computing a tall output table with a single
    reshape column from a wide input table with
    56 reshape columns and
    a variable number of rows
    (x axis). \textbf{Top} panel shows
    functions which provide some wide-to-tall data reshaping
    functionality; \textbf{Bottom} panel shows only the functions
    which output capture columns based on a regular expression.}
  \label{fig:timings-single-rows}
\end{figure}

Second, we performed similar timings on variants of the WHO data with
a variable number of columns, and the original number of rows
(7240). The desired output again has a single reshape output column,
and we tried the same two regular expressions and type conversions as
in the tests described earlier in this section. We
observed similar asymptotic trends as in the previous comparison
(Figure~\ref{fig:timings-single-cols}). These data indicate that for
converting data into a single reshape output column, \pkg{nc} has
similar or faster speeds than comparable R packages.

% > stats.timings[`capture groups`==3][N.col==max(N.col), .(N.col, expr, median)][order(median)]

%    N.col                     expr      median
% 1:  1796             utils::stack  0.09102206
% 2:  1796           reshape2::melt  0.24715609
% 3:  1796         data.table::melt  0.28116050
% 4:  1796            tidyr::gather  0.43337657
% 5:  1796 cdata::unpivot_to_blocks  0.68150276
% 6:  1796      tidyr::pivot_longer  1.15550911
% 7:  1796  nc::capture_melt_single  1.48272495
% 8:  1796           stats::reshape 15.67225194
% > stats.timings[`capture groups`==5][N.col==max(N.col), .(N.col, expr, mean, sd)][order(-mean)]
%    N.col                    expr     mean         sd
% 1:  5660     tidyr::pivot_longer 8.481555 0.09183717
% 2:  5660 nc::capture_melt_single 1.256046 0.07065709
% > 

\begin{figure}
  \centering
  \includegraphics[width = \textwidth]{figure-who-both-cols.pdf}
  \caption{
    \vskip -0.5cm
    Timings for computing a tall output table with a single
    reshape column from a wide input table
    with 7240 rows and a variable number of columns to
    reshape    
    (x axis).
    \textbf{Top} panel shows functions which provide some
    wide-to-tall data reshaping functionality; \textbf{Bottom} panel
    shows only the functions which output capture columns based
    on a regular expression.}
  \label{fig:timings-single-cols}
\end{figure}

Third, we performed timings on variants of the iris data with a
variable number of rows, and twice the original number of reshape
columns (8). The input reshape column names were of the form
\code{day1.Sepal.Length}, \code{day2.Sepal.Length},
\code{day1.Sepal.Width}, etc. Since the desired output has two reshape
columns (\code{Sepal} and \code{Petal}), we considered packages which
support multiple output columns (\pkg{cdata}, \pkg{stats},
\pkg{tidyr}, \pkg{nc}, \pkg{data.table}). As in the previous tests, we
tried one experiment without type conversions (for which we tested all
packages), and one experiment with
type conversion (for which we only tested \pkg{tidyr} and  \pkg{nc}).
%In both experiments we used a regular expression with
%three capture groups (\code{day}, \code{part}, \code{dim}). 
In both experiments we observed that all algorithms have similar
asymptotic time complexity (Figure~\ref{fig:timings-multiple-rows}). We
observed that \pkg{nc} is slightly faster than \pkg{cdata} and
\pkg{stats}, and slightly slower than \code{data.table} (by constant
factors).

\begin{figure}
  \centering 
  \includegraphics[width = \textwidth]{figure-iris-rows.pdf}
  \caption{
    Timings for computing a tall output table with multiple (2)
    reshape columns from a wide input table with
    8 reshape columns and
    a variable number of rows
    (x axis).
    \textbf{Top} panel shows functions which provide some
    wide-to-tall data reshaping functionality; \textbf{Bottom} panel
    shows only the functions which output capture columns based on a
    regular expression.}
  \label{fig:timings-multiple-rows}
\end{figure}

Finally, we performed similar timings on variants of the iris data
with a variable number of columns, and the original number of rows
(150). Again there are three desired reshape output columns, and we
tested a regular expression with three capture groups (with or without
type conversion). As in previous experiments, we expected that all
functions would have similar asymptotic time complexity. Surprisingly,
we observed that \pkg{nc} and \pkg{data.table} have smaller slopes on
the log-log plot, which implies that they asymptotically faster than
the other packages (Figure~\ref{fig:timings-multiple-cols}). These
data suggest that \pkg{nc} or \pkg{data.table} should be preferred
over the other packages (\pkg{cdata}, \pkg{stats}, \pkg{tidyr}) for
fast conversion into multiple reshape output columns when there are
many input reshape columns. Overall, our experiments indicate that
for converting data to multiple reshape output columns, \pkg{nc} has
similar or faster speeds than comparable R packages.

\begin{figure}
  \centering 
  \includegraphics[width = \textwidth]{figure-iris-cols.pdf}
  \caption{    
    Timings for computing a tall output table with multiple
    reshape columns (2) from a wide input table
    with 150 rows and a variable number of columns to
    reshape    
    (x axis).
    Timings for wide-to-tall data reshaping on an input data
    table with 150 rows and a variable number of columns to
    reshape (x axis). \textbf{Top} panel shows functions which provide some
    wide-to-tall data reshaping functionality; \textbf{Bottom} panel
    shows only the functions which output capture columns based
    on a regular expression.}
  \label{fig:timings-multiple-cols}
\end{figure}

\section{Discussion and conclusions}

In this paper we described the new functions in \pkg{nc} for data
reshaping using regular expressions. The \pkg{nc} package allows a
user to define a regular expression in R code, along with capture
group names and corresponding type conversion functions. We showed how
this syntax makes it easy to define complex regular expressions in
terms of simpler sub-patterns, while providing a uniform interface to
three regex engines (ICU, PCRE, RE2). We showed several examples of
how \pkg{nc} can be used for parsing non-tabular text data, and for
wide-to-tall data reshaping. We provided a detailed comparison with
other R packages in terms of syntax, functionality, and computation
time.

In all of our speed comparisons, we observed that \pkg{nc} is at least
as fast as comparable R packages. In general, we observed that other
functions which provide fewer features are slightly faster, and other
functions which provide more features are slightly slower (by constant
factors). For example, the fastest function for converting data into a
single reshape output column was \code{utils::stack}. This empirical
observation is consistent with our theoretical assessment of this
function (Table\ref{tab:features}); since it provides the fewest
features, it does the least amount of work, and should be the
fastest. 

The \code{tidyr::pivot\_longer} function provides a feature set which
is most similar to \pkg{nc}. We showed that both packages can perform
the same data reshaping operations, but with different syntax. When
the input reshape column names are regular, \pkg{nc} may be preferable
in order to avoid repetition and to support a wider range of possible
type conversions. Also, our empirical timings suggest that \pkg{nc}
is faster when there are type conversions, or when there are many
input reshape columns and multiple output reshape columns.

We observed a surprising result in our empirical timings with multiple
reshape output columns and a variable number of reshape input
columns. We expected that all of the packages would have similar
asymptotic timings (differing only in terms of constant
factors). However we observed that \pkg{nc} and its dependent package
\pkg{data.table} had much faster asymptotic timings than other R
packages (\pkg{cdata}, \pkg{stats}, \pkg{tidyr}). This result suggests
that the speed of these other packages could be improved by adopting
the algorithm used in the \pkg{data.table} package.

In \pkg{nc} there are two different functions for wide-to-tall data
reshaping: \code{nc::capture\_melt\_single} computes a single output
reshape column, and \code{nc::capture\_melt\_multiple} computes
multiple output reshape columns. In contrast, other functions that
support multiple output reshape columns also support a single output
reshape column (Table\ref{tab:features}). It is natural to ask whether
these two \pkg{nc} functions could be combined into a single function
that could handle both kinds of output. Of course it is possible, but
we prefer to keep the two functions separate in order to provide more
specific/informative documentation, examples, and error messages.

We have shown how the \pkg{nc} package provides a powerful and
efficient new syntax for wide-to-tall data reshaping using regular
expressions. The inverse operation, tall-to-wide data reshaping, is
not supported; the focus in \pkg{nc} is regular expressions, which are
not useful for tall-to-wide reshaping operations. Instead, we
recommend using \pkg{data.table}, which provides an efficient
implementation of tall-to-wide reshaping operations. For future work,
we are interested to explore other operations related to machine
learning and data visualization which could be simplified using
regular expressions.

\paragraph{Reproducible research statement.} The source code for this
article can be freely downloaded from
\url{https://github.com/tdhock/nc-article}

\bibliography{hocking}

\address{Toby Dylan Hocking\\
  School of Informatics, Computing, and Cyber Systems\\
  Northern Arizona University\\
  Flagstaff, Arizona\\
  USA\\
  \email{toby.hocking@nau.edu}}

